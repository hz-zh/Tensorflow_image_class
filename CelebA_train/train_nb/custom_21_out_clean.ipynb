{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "555gxJm1aZd8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCiSGW65aY-s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Set variable to image directory\n",
        "img_dir = '/content/drive/My Drive/CelebA/Img/img_align_celeba_6500'\n",
        "check_save_dir = '/content/drive/My Drive/CelebA/Checkpoints'\n",
        "\n",
        "# Define list of class names (subset of the classes listed in `list_attr_celeba.txt`)\n",
        "class_names = [\"Arched_Eyebrows\", \"Bags_Under_Eyes\", \"Bangs\", \"Black_Hair\", \"Blond_Hair\", \"Brown_Hair\", \"Eyeglasses\", \"Gray_Hair\", \"Heavy_Makeup\", \"High_Cheekbones\", \"Mouth_Slightly_Open\", \"Mustache\", \"Narrow_Eyes\", \"Rosy_Cheeks\", \"Smiling\", \"Straight_Hair\", \"Wavy_Hair\", \"Wearing_Earrings\", \"Wearing_Hat\", \"Wearing_Lipstick\", \"Wearing_Necklace\"]\n",
        "\n",
        "# Define df as a dataframe from directory \n",
        "df=pd.read_csv('/content/drive/My Drive/CelebA/Anno/labels.csv', header=0, delimiter=',', usecols=None, names=[\"filenames\", \"Arched_Eyebrows\", \"Bags_Under_Eyes\", \"Bangs\", \"Black_Hair\", \"Blond_Hair\", \"Brown_Hair\", \"Eyeglasses\", \"Gray_Hair\", \"Heavy_Makeup\", \"High_Cheekbones\", \"Mouth_Slightly_Open\", \"Mustache\", \"Narrow_Eyes\", \"Rosy_Cheeks\", \"Smiling\", \"Straight_Hair\", \"Wavy_Hair\", \"Wearing_Earrings\", \"Wearing_Hat\", \"Wearing_Lipstick\", \"Wearing_Necklace\"])\n",
        "print(df)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, valid = train_test_split(df, test_size = 0.3)\n",
        "valid, test = train_test_split(valid, test_size=0.2)\n",
        "train_features = train[[\"Arched_Eyebrows\", \"Bags_Under_Eyes\", \"Bangs\", \"Black_Hair\", \"Blond_Hair\", \"Brown_Hair\", \"Eyeglasses\", \"Gray_Hair\", \"Heavy_Makeup\", \"High_Cheekbones\", \"Mouth_Slightly_Open\", \"Mustache\", \"Narrow_Eyes\", \"Rosy_Cheeks\", \"Smiling\", \"Straight_Hair\", \"Wavy_Hair\", \"Wearing_Earrings\", \"Wearing_Hat\", \"Wearing_Lipstick\", \"Wearing_Necklace\"]]\n",
        "print(train,valid,test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvN-ccTMsZA5"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "%pip install git+https://github.com/keras-team/keras-preprocessing.git\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import os, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZed-TvEDu9n"
      },
      "outputs": [],
      "source": [
        "# Reproducability\n",
        "def set_seed(seed=31415):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    #os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "set_seed()\n",
        "\n",
        "# Load training and validation sets\n",
        "datagen=ImageDataGenerator(rescale=1./255., \n",
        "                          rotation_range=20,\n",
        "                          horizontal_flip=True,\n",
        "                          vertical_flip=True,\n",
        "                          width_shift_range=0.2,\n",
        "                          height_shift_range=0.2,)\n",
        "valid_datagen=ImageDataGenerator(rescale=1./255.,\n",
        "                                rotation_range=20,\n",
        "                                horizontal_flip=True,\n",
        "                                vertical_flip=True,\n",
        "                                width_shift_range=0.2,\n",
        "                                height_shift_range=0.2,)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train,\n",
        "    directory=img_dir,\n",
        "    x_col='filenames',\n",
        "    y_col=class_names,\n",
        "    save_format='jpg',\n",
        "    batch_size=35,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"raw\",\n",
        "    target_size=(128, 128)\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_dataframe(\n",
        "    dataframe=valid,\n",
        "    directory=img_dir,\n",
        "    x_col='filenames',\n",
        "    y_col=class_names,\n",
        "    save_format='jpg',\n",
        "    batch_size=30,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"raw\",\n",
        "    target_size=(128, 128)\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test,\n",
        "    directory=img_dir,\n",
        "    x_col='filenames',\n",
        "    batch_size=1,\n",
        "    seed=42,\n",
        "    shuffle=False,\n",
        "    class_mode=None,\n",
        "    target_size=(128, 128)\n",
        ")\n",
        "\n",
        "# Data Pipeline\n",
        "def convert_to_float(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    return image, label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "ds_train = tf.data.Dataset.from_generator(\n",
        "    lambda: train_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, 128, 128, 3], [None, len(class_names)])\n",
        ").map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "ds_valid = tf.data.Dataset.from_generator(\n",
        "    lambda: valid_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, 128, 128, 3], [None, len(class_names)])\n",
        ").map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "ds_test = tf.data.Dataset.from_generator(\n",
        "    lambda: test_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, 128, 128, 3], [None, len(class_names)])\n",
        ").map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hGHitkgG9Bv"
      },
      "outputs": [],
      "source": [
        "ds_test = tf.data.Dataset.from_generator(\n",
        "    lambda: test_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, 128, 128, 3], [None, len(class_names)])\n",
        ").map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJrQ6GS3eZi_"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwnFfST3bt9l"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.layers.Input(shape=(128, 128, 3))\n",
        "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "output1 = tf.keras.layers.Dense(1, activation='sigmoid', name='Arched_Eyebrows')(x)\n",
        "output2 = tf.keras.layers.Dense(1, activation='sigmoid', name='Bags_Under_Eyes')(x)\n",
        "output3 = tf.keras.layers.Dense(1, activation='sigmoid', name='Bangs')(x)\n",
        "output4 = tf.keras.layers.Dense(1, activation='sigmoid', name='Black_Hair')(x)\n",
        "output5 = tf.keras.layers.Dense(1, activation='sigmoid', name='Blond_Hair')(x)\n",
        "output6 = tf.keras.layers.Dense(1, activation='sigmoid', name='Brown_Hair')(x)\n",
        "output7 = tf.keras.layers.Dense(1, activation='sigmoid', name='Eyeglasses')(x)\n",
        "output8 = tf.keras.layers.Dense(1, activation='sigmoid', name='Gray_Hair')(x)\n",
        "output9 = tf.keras.layers.Dense(1, activation='sigmoid', name='Heavy_Makeup')(x)\n",
        "output10 = tf.keras.layers.Dense(1, activation='sigmoid', name='High_Cheekbones')(x)\n",
        "output11 = tf.keras.layers.Dense(1, activation='sigmoid', name='Mouth_Slightly_Open')(x)\n",
        "output12 = tf.keras.layers.Dense(1, activation='sigmoid', name='Mustache')(x)\n",
        "output13 = tf.keras.layers.Dense(1, activation='sigmoid', name='Narrow_Eyes')(x)\n",
        "output14 = tf.keras.layers.Dense(1, activation='sigmoid', name='Rosy_Cheeks')(x)\n",
        "output15 = tf.keras.layers.Dense(1, activation='sigmoid', name='Smiling')(x)\n",
        "output16 = tf.keras.layers.Dense(1, activation='sigmoid', name='Straight_Hair')(x)\n",
        "output17 = tf.keras.layers.Dense(1, activation='sigmoid', name='Wavy_Hair')(x)\n",
        "output18 = tf.keras.layers.Dense(1, activation='sigmoid', name='Wearing_Earrings')(x)\n",
        "output19 = tf.keras.layers.Dense(1, activation='sigmoid', name='Wearing_Hat')(x)\n",
        "output20 = tf.keras.layers.Dense(1, activation='sigmoid', name='Wearing_Lipstick')(x)\n",
        "output21 = tf.keras.layers.Dense(1, activation='sigmoid', name='Wearing_Necklace')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=[\n",
        "                                                      output1,\n",
        "                                                      output2,\n",
        "                                                      output3,\n",
        "                                                      output4,\n",
        "                                                      output5,\n",
        "                                                      output6,\n",
        "                                                      output7,\n",
        "                                                      output8,\n",
        "                                                      output9, \n",
        "                                                      output10,\n",
        "                                                      output11,\n",
        "                                                      output12,\n",
        "                                                      output13,\n",
        "                                                      output14,\n",
        "                                                      output15,\n",
        "                                                      output16,\n",
        "                                                      output17,\n",
        "                                                      output18,\n",
        "                                                      output19,\n",
        "                                                      output20,\n",
        "                                                      output21\n",
        "                                                      ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-wn5OzfZFHZ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss={'Arched_Eyebrows': 'binary_crossentropy', \n",
        "              'Bags_Under_Eyes': 'binary_crossentropy',\n",
        "              'Bangs': 'binary_crossentropy',\n",
        "              'Black_Hair': 'binary_crossentropy',\n",
        "              'Blond_Hair': 'binary_crossentropy',\n",
        "              'Brown_Hair': 'binary_crossentropy',\n",
        "              'Eyeglasses': 'binary_crossentropy',\n",
        "              'Gray_Hair': 'binary_crossentropy',\n",
        "              'Heavy_Makeup': 'binary_crossentropy',\n",
        "              'High_Cheekbones': 'binary_crossentropy',\n",
        "              'Mouth_Slightly_Open': 'binary_crossentropy',\n",
        "              'Mustache': 'binary_crossentropy',\n",
        "              'Narrow_Eyes': 'binary_crossentropy',\n",
        "              'Rosy_Cheeks': 'binary_crossentropy',\n",
        "              'Smiling': 'binary_crossentropy',\n",
        "              'Straight_Hair': 'binary_crossentropy',\n",
        "              'Wavy_Hair': 'binary_crossentropy',\n",
        "              'Wearing_Earrings': 'binary_crossentropy',\n",
        "              'Wearing_Hat': 'binary_crossentropy',\n",
        "              'Wearing_Lipstick': 'binary_crossentropy',\n",
        "              'Wearing_Necklace': 'binary_crossentropy'\n",
        "              },\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnvj7wbvb33_"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAPLgvo2jh6e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    check_save_dir,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    monitor='loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# define early stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='loss', # metric to monitor for early stopping\n",
        "    patience=5, # number of epochs to wait before stopping\n",
        "    restore_best_weights=True, # restore the best model weights found during training\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4ISbZCwryRO"
      },
      "outputs": [],
      "source": [
        "def generator_wrapper(dataset):\n",
        "    for batch_x, batch_y in dataset:\n",
        "        yield (batch_x, [batch_y[:, i] for i in range(21)])\n",
        "        \n",
        "ds_train_wrapped = generator_wrapper(ds_train)\n",
        "ds_valid_wrapped = generator_wrapper(ds_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIL4O2MQWCGU"
      },
      "outputs": [],
      "source": [
        "%cd drive/My Drive/CelebA/Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJa6-jricD4w"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "                    ds_train_wrapped, \n",
        "                    epochs=20, \n",
        "                    validation_data=ds_valid_wrapped, \n",
        "                    batch_size=35, \n",
        "                    steps_per_epoch=35, \n",
        "                    validation_steps=30,\n",
        "                    verbose=1,\n",
        "                    callbacks=[checkpoint, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qn_aP5yKlxf"
      },
      "outputs": [],
      "source": [
        "%cd ../Saved_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er2a0WPHH7tk"
      },
      "outputs": [],
      "source": [
        "tf.keras.saving.save_model(\n",
        "    model, 'model_01.tf', overwrite=False, save_format='tf',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJJnh1eyDo90"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test data\n",
        "def test_generator_wrapper(dataset):\n",
        "    for batch_x, batch_y in dataset:\n",
        "        yield (batch_x, tuple(batch_y[:, i] for i in range(21)))\n",
        "\n",
        "ds_test_wrapped = test_generator_wrapper(ds_test)\n",
        "test_loss, test_metrics = model.evaluate(ds_test_wrapped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZufnzIZvcSjS"
      },
      "outputs": [],
      "source": [
        "# Set Matplotlib defaults\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('image', cmap='magma')\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Val_Accuracy')\n",
        "\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, [ \n",
        "                  'val_Arched_Eyebrows_accuracy',\n",
        "                  'val_Bags_Under_Eyes_accuracy',\n",
        "                  'val_Bangs_accuracy',\n",
        "                  'val_Black_Hair_accuracy',\n",
        "                  'val_Blond_Hair_accuracy',\n",
        "                     ]].plot()\n",
        "history_frame.loc[:, [\n",
        "                  'val_Brown_Hair_accuracy',\n",
        "                  'val_Eyeglasses_accuracy',\n",
        "                  'val_Gray_Hair_accuracy',\n",
        "                  'val_Heavy_Makeup_accuracy',\n",
        "                  'val_High_Cheekbones_accuracy',\n",
        "                     ]].plot()\n",
        "history_frame.loc[:, [\n",
        "                  'val_Mouth_Slightly_Open_accuracy',\n",
        "                  'val_Mustache_accuracy',\n",
        "                  'val_Narrow_Eyes_accuracy',\n",
        "                  'val_Rosy_Cheeks_accuracy',\n",
        "                  'val_Smiling_accuracy',\n",
        "                     ]].plot()\n",
        "history_frame.loc[:, [\n",
        "                  'val_Straight_Hair_accuracy',\n",
        "                  'val_Wavy_Hair_accuracy',\n",
        "                  'val_Wearing_Earrings_accuracy',\n",
        "                  'val_Wearing_Hat_accuracy',\n",
        "                  'val_Wearing_Lipstick_accuracy',\n",
        "                  'val_Wearing_Necklace_accuracy',\n",
        "                  ]].plot()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
