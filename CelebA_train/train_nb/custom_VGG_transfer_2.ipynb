{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "555gxJm1aZd8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvN-ccTMsZA5"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "%pip install git+https://github.com/keras-team/keras-preprocessing.git\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCiSGW65aY-s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "img_dir = '/content/drive/My Drive/CelebA/Img/img_align_celeba_32500'\n",
        "# Load labels.csv\n",
        "labels_df = pd.read_csv('/content/drive/My Drive/CelebA/Anno/labels_even.csv', header=0, names=['Filename', 'High_Cheekbones', 'Mouth_Slightly_Open', 'Smiling']) \n",
        "# enforce that the columns are of type int, except for 'Filename'\n",
        "labels_df['High_Cheekbones'] = labels_df['High_Cheekbones'].astype(int)\n",
        "labels_df['Mouth_Slightly_Open'] = labels_df['Mouth_Slightly_Open'].astype(int)\n",
        "labels_df['Smiling'] = labels_df['Smiling'].astype(int)\n",
        "\n",
        "\n",
        "# Load list_bbox_celeba.txt\n",
        "bbox_df = pd.read_csv('/content/drive/My Drive/CelebA/Anno/list_bbox_celeba.txt', delim_whitespace=True, header=1, dtype=object) \n",
        "\n",
        "# rename the first column of bbox_df to 'Filename'\n",
        "bbox_df.rename(columns={\"image_id\": \"Filename\"}, inplace=True)\n",
        "\n",
        "# Convert 'x_1', 'y_1', 'width' and 'height' columns of bbox_df to numeric\n",
        "bbox_df['x_1'] = pd.to_numeric(bbox_df['x_1'])\n",
        "bbox_df['y_1'] = pd.to_numeric(bbox_df['y_1'])\n",
        "bbox_df['width'] = pd.to_numeric(bbox_df['width'])\n",
        "bbox_df['height'] = pd.to_numeric(bbox_df['height'])\n",
        "\n",
        "# Merge labels_df and bbox_df\n",
        "merged_df = pd.merge(labels_df, bbox_df, on='Filename')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAbA15u9sYgD"
      },
      "outputs": [],
      "source": [
        "merged_df['x_normalized'] = merged_df['x_1'] / merged_df['width']\n",
        "merged_df['y_normalized'] = merged_df['y_1'] / merged_df['height']\n",
        "merged_df['width_normalized'] = merged_df['width'] / merged_df['width']\n",
        "merged_df['height_normalized'] = merged_df['height'] / merged_df['height']\n",
        "\n",
        "# remove columns 'x_1', 'y_1', 'width' and 'height'\n",
        "merged_df.drop(['x_1', 'y_1', 'width', 'height'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jmt7Tunzsi0-"
      },
      "outputs": [],
      "source": [
        "train, valid = train_test_split(merged_df, test_size = 0.3)\n",
        "valid, test = train_test_split(valid, test_size=0.2)\n",
        "train_features = train[[\"High_Cheekbones\", \"Mouth_Slightly_Open\",\"Smiling\"]]\n",
        "# print length of train, valid and test\n",
        "print(\"train: \", len(train))\n",
        "print(\"valid: \", len(valid))\n",
        "print(\"test: \", len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove a random row from train\n",
        "train = train.drop(train.sample().index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZed-TvEDu9n"
      },
      "outputs": [],
      "source": [
        "# Define list of class names (subset of the classes listed in `list_attr_celeba.txt`)\n",
        "class_names = [\"High_Cheekbones\", \"Mouth_Slightly_Open\", \"Smiling\"]\n",
        "\n",
        "# Reproducability\n",
        "def set_seed(seed=31415):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    #os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "set_seed()\n",
        "\n",
        "def custom_augmentation(np_tensor):\n",
        "\n",
        "  def random_contrast(np_tensor):\n",
        "    return tf.image.random_contrast(np_tensor, 0.5, 2)\n",
        "\n",
        "  augmnted_tensor = random_contrast(np_tensor)\n",
        "  return np.array(augmnted_tensor)\n",
        "\n",
        "# Load training and validation sets\n",
        "datagen=ImageDataGenerator(rescale=1./255.,\n",
        "                          rotation_range=45,\n",
        "                          horizontal_flip=True,\n",
        "                          vertical_flip=True,\n",
        "                          preprocessing_function=custom_augmentation)\n",
        "valid_datagen=ImageDataGenerator(rescale=1./255.,\n",
        "                                rotation_range=45,\n",
        "                                horizontal_flip=True,\n",
        "                                vertical_flip=True,\n",
        "                                preprocessing_function=custom_augmentation)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train,\n",
        "    directory=img_dir,\n",
        "    x_col='Filename',\n",
        "    y_col=class_names,\n",
        "    save_format='jpg',\n",
        "    batch_size=25,\n",
        "    seed=42,\n",
        "    shuffle=False,\n",
        "    class_mode=\"raw\",\n",
        "    target_size=(178, 218)\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_dataframe(\n",
        "    dataframe=valid,\n",
        "    directory=img_dir,\n",
        "    x_col='Filename',\n",
        "    y_col=class_names,\n",
        "    save_format='jpg',\n",
        "    batch_size=25,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"raw\",\n",
        "    target_size=(178, 218)\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test,\n",
        "    directory=img_dir,\n",
        "    x_col='Filename',\n",
        "    batch_size=15,\n",
        "    seed=42,\n",
        "    shuffle=False,\n",
        "    class_mode=None,\n",
        "    target_size=(178, 218)\n",
        ")\n",
        "\n",
        "# Data Pipeline\n",
        "def convert_to_float(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    return image, label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "ds_train = tf.data.Dataset.from_generator(\n",
        "    lambda: train_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, 128, 128, 3], [None, len(class_names)])\n",
        ").map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "ds_valid = tf.data.Dataset.from_generator(\n",
        "    lambda: valid_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, 128, 128, 3], [None, len(class_names)])\n",
        ").map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "'''ds_test = tf.data.Dataset.from_generator(\n",
        "    lambda: test_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, 128, 128, 3], [None, len(class_names)])\n",
        ").map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJrQ6GS3eZi_"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9jPf9OsuzrX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "\n",
        "# Load pre-trained VGG16 model without top layers\n",
        "base_model = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(218, 178, 3)\n",
        ")\n",
        "\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Define input layer (adjust the shape based on your input images)\n",
        "input_tensor = Input(shape=(218, 178, 3), name='input_01')\n",
        "\n",
        "# Pass input through VGG16 base model\n",
        "x = base_model(input_tensor)\n",
        "\n",
        "# Add GlobalAveragePooling2D layer to reduce spatial dimensions\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Add output layer for class predictions\n",
        "output_1 = Dense(1, activation='softmax', name='High_Cheekbones')(x)\n",
        "output_2 = Dense(1, activation='softmax', name='Mouth_Slightly_Open')(x)\n",
        "output_3 = Dense(1, activation='softmax', name='Smiling')(x)\n",
        "\n",
        "# Create the model with a specific name\n",
        "model = Model(inputs=input_tensor, outputs = [output_1, output_2, output_3], name='VGG16_transfer')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={'High_Cheekbones': 'binary_crossentropy', 'Mouth_Slightly_Open': 'binary_crossentropy', 'Smiling': 'binary_crossentropy'},\n",
        "    metrics=['accuracy', 'precision', 'recall']\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAPLgvo2jh6e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "gc.enable()\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    check_save_dir,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    monitor='loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        "    )\n",
        "\n",
        "# define early stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='loss', # metric to monitor for early stopping\n",
        "    patience=3, # number of epochs to wait before stopping\n",
        "    restore_best_weights=True, # restore the best model weights found during training\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4ISbZCwryRO"
      },
      "outputs": [],
      "source": [
        "def generator_wrapper(dataset):\n",
        "    for batch_x, batch_y in dataset:\n",
        "        yield (batch_x, [batch_y[:, i] for i in range(21)])\n",
        "\n",
        "ds_train_wrapped = generator_wrapper(ds_train)\n",
        "ds_valid_wrapped = generator_wrapper(ds_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qn_aP5yKlxf"
      },
      "outputs": [],
      "source": [
        "%cd drive/My Drive/CelebA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnbTpgq1Pill"
      },
      "outputs": [],
      "source": [
        "model.load_weights('./Checkpoints/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CtiwMoKSRCJ"
      },
      "source": [
        "Train Data: 6,300 rows   \n",
        "Train Batch Size: 30 images  \n",
        "Train Step Size = $6300/30 = 210$  \n",
        "\n",
        "-------\n",
        "Valid Data: 2160 rows  \n",
        "Valid Batch Size: 30 images  \n",
        "Valid Step Size: $2160 / 30 = 72$  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Epoch 1/10\n",
        "210/210 [==============================] - ETA: 0s - loss: 1.3464 - High_Cheekbones_loss: 0.4780 - Mouth_Slightly_Open_loss: 0.4777 - Smiling_loss: 0.3907 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690 \n",
        "Epoch 1: loss improved from inf to 1.34644, saving model to /content/drive/My Drive/CelebA/Checkpoints_3_Classes/\n",
        "210/210 [==============================] - 6017s 28s/step - loss: 1.3464 - High_Cheekbones_loss: 0.4780 - Mouth_Slightly_Open_loss: 0.4777 - Smiling_loss: 0.3907 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690 - val_loss: 1.3307 - val_High_Cheekbones_loss: 0.4712 - val_Mouth_Slightly_Open_loss: 0.4708 - val_Smiling_loss: 0.3886 - val_High_Cheekbones_accuracy: 0.8204 - val_Mouth_Slightly_Open_accuracy: 0.8204 - val_Smiling_accuracy: 0.8694\n",
        "Epoch 2/10\n",
        "210/210 [==============================] - ETA: 0s - loss: 1.3414 - High_Cheekbones_loss: 0.4747 - Mouth_Slightly_Open_loss: 0.4772 - Smiling_loss: 0.3895 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690\n",
        "Epoch 2: loss improved from 1.34644 to 1.34137, saving model to /content/drive/My Drive/CelebA/Checkpoints_3_Classes/\n",
        "210/210 [==============================] - 162s 776ms/step - loss: 1.3414 - High_Cheekbones_loss: 0.4747 - Mouth_Slightly_Open_loss: 0.4772 - Smiling_loss: 0.3895 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690 - val_loss: 1.3307 - val_High_Cheekbones_loss: 0.4733 - val_Mouth_Slightly_Open_loss: 0.4674 - val_Smiling_loss: 0.3899 - val_High_Cheekbones_accuracy: 0.8190 - val_Mouth_Slightly_Open_accuracy: 0.8227 - val_Smiling_accuracy: 0.8681\n",
        "Epoch 3/10\n",
        "210/210 [==============================] - ETA: 0s - loss: 1.3533 - High_Cheekbones_loss: 0.4800 - Mouth_Slightly_Open_loss: 0.4816 - Smiling_loss: 0.3917 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690\n",
        "Epoch 3: loss did not improve from 1.34137\n",
        "210/210 [==============================] - 160s 765ms/step - loss: 1.3533 - High_Cheekbones_loss: 0.4800 - Mouth_Slightly_Open_loss: 0.4816 - Smiling_loss: 0.3917 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690 - val_loss: 1.3299 - val_High_Cheekbones_loss: 0.4732 - val_Mouth_Slightly_Open_loss: 0.4702 - val_Smiling_loss: 0.3864 - val_High_Cheekbones_accuracy: 0.8190 - val_Mouth_Slightly_Open_accuracy: 0.8208 - val_Smiling_accuracy: 0.8704\n",
        "Epoch 4/10\n",
        "210/210 [==============================] - ETA: 0s - loss: 1.3406 - High_Cheekbones_loss: 0.4742 - Mouth_Slightly_Open_loss: 0.4772 - Smiling_loss: 0.3892 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690\n",
        "Epoch 4: loss improved from 1.34137 to 1.34061, saving model to /content/drive/My Drive/CelebA/Checkpoints_3_Classes/\n",
        "210/210 [==============================] - 156s 746ms/step - loss: 1.3406 - High_Cheekbones_loss: 0.4742 - Mouth_Slightly_Open_loss: 0.4772 - Smiling_loss: 0.3892 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690 - val_loss: 1.3325 - val_High_Cheekbones_loss: 0.4717 - val_Mouth_Slightly_Open_loss: 0.4724 - val_Smiling_loss: 0.3884 - val_High_Cheekbones_accuracy: 0.8199 - val_Mouth_Slightly_Open_accuracy: 0.8194 - val_Smiling_accuracy: 0.8690\n",
        "Epoch 5/10\n",
        "210/210 [==============================] - ETA: 0s - loss: 1.3409 - High_Cheekbones_loss: 0.4749 - Mouth_Slightly_Open_loss: 0.4772 - Smiling_loss: 0.3889 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690\n",
        "Epoch 5: loss did not improve from 1.34061\n",
        "210/210 [==============================] - 149s 711ms/step - loss: 1.3409 - High_Cheekbones_loss: 0.4749 - Mouth_Slightly_Open_loss: 0.4772 - Smiling_loss: 0.3889 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690 - val_loss: 1.3345 - val_High_Cheekbones_loss: 0.4717 - val_Mouth_Slightly_Open_loss: 0.4781 - val_Smiling_loss: 0.3846 - val_High_Cheekbones_accuracy: 0.8199 - val_Mouth_Slightly_Open_accuracy: 0.8157 - val_Smiling_accuracy: 0.8713\n",
        "Epoch 6/10\n",
        "210/210 [==============================] - ETA: 0s - loss: 1.3413 - High_Cheekbones_loss: 0.4747 - Mouth_Slightly_Open_loss: 0.4773 - Smiling_loss: 0.3894 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690\n",
        "Epoch 6: loss did not improve from 1.34061\n",
        "210/210 [==============================] - 137s 653ms/step - loss: 1.3413 - High_Cheekbones_loss: 0.4747 - Mouth_Slightly_Open_loss: 0.4773 - Smiling_loss: 0.3894 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690 - val_loss: 1.3176 - val_High_Cheekbones_loss: 0.4666 - val_Mouth_Slightly_Open_loss: 0.4609 - val_Smiling_loss: 0.3901 - val_High_Cheekbones_accuracy: 0.8231 - val_Mouth_Slightly_Open_accuracy: 0.8269 - val_Smiling_accuracy: 0.8681\n",
        "Epoch 7/10\n",
        "210/210 [==============================] - ETA: 0s - loss: 1.3418 - High_Cheekbones_loss: 0.4747 - Mouth_Slightly_Open_loss: 0.4783 - Smiling_loss: 0.3887 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690\n",
        "Epoch 7: loss did not improve from 1.34061\n",
        "210/210 [==============================] - 131s 624ms/step - loss: 1.3418 - High_Cheekbones_loss: 0.4747 - Mouth_Slightly_Open_loss: 0.4783 - Smiling_loss: 0.3887 - High_Cheekbones_accuracy: 0.8186 - Mouth_Slightly_Open_accuracy: 0.8167 - Smiling_accuracy: 0.8690 - val_loss: 1.3449 - val_High_Cheekbones_loss: 0.4768 - val_Mouth_Slightly_Open_loss: 0.4729 - val_Smiling_loss: 0.3952 - val_High_Cheekbones_accuracy: 0.8167 - val_Mouth_Slightly_Open_accuracy: 0.8190 - val_Smiling_accuracy: 0.8662"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Epoch, Epoch time, Step time  \n",
        "1, 9870s, 47s   \n",
        "2, 6017s, 28s\n",
        "3, 162s, 0.776s\n",
        "4, 160s, 0.765s\n",
        "5, 156s, 0.746s\n",
        "6, 149s, 0.711s\n",
        "7, 137s, 0.653s\n",
        "8, 131s, 0.624s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJa6-jricD4w"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "                    ds_train_wrapped,\n",
        "                    epochs=10,\n",
        "                    validation_data=ds_valid_wrapped,\n",
        "                    batch_size=30,\n",
        "                    steps_per_epoch=210,\n",
        "                    validation_steps=72,\n",
        "                    verbose=1,\n",
        "                    callbacks=[checkpoint, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szL1KVSw6Ysc"
      },
      "outputs": [],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d-RMOoSxidG"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KKZqT8w2_d-"
      },
      "outputs": [],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er2a0WPHH7tk"
      },
      "outputs": [],
      "source": [
        "tf.keras.saving.save_model(\n",
        "    model, './Saved_models/Set_B/model_03', overwrite=False, save_format='tf',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBQ3xuX1cPpO"
      },
      "outputs": [],
      "source": [
        "reconstructed_model = keras.models.load_model(\"./Saved_models/Set_B/model_15\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YeSysLydJgI"
      },
      "outputs": [],
      "source": [
        "reconstructed_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkEUOEnNHiGN"
      },
      "outputs": [],
      "source": [
        "reconstructed_model.load_weights('./Checkpoints/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FoM-unmcola"
      },
      "outputs": [],
      "source": [
        "history = reconstructed_model.fit(\n",
        "                    ds_train_wrapped,\n",
        "                    epochs=1,\n",
        "                    validation_data=ds_valid_wrapped,\n",
        "                    batch_size=25,\n",
        "                    steps_per_epoch=910,\n",
        "                    validation_steps=312,\n",
        "                    verbose=1,\n",
        "                    callbacks=[checkpoint, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5XEPUEJGyGv"
      },
      "outputs": [],
      "source": [
        "tf.keras.saving.save_model(\n",
        "    reconstructed_model, './Saved_models/Set_B/model_15', overwrite=False, save_format='tf',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB0MHpzcvn5P"
      },
      "outputs": [],
      "source": [
        "test_generator.reset()\n",
        "# Get the predicted probabilities for each class\n",
        "predictions = reconstructed_model.predict(test_generator, steps=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6zmv1UyII1g"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from textwrap import wrap\n",
        "imagePreds = []\n",
        "\n",
        "#print(predictions[20][14][0])\n",
        "for i in range(21):\n",
        "  classPreds = []\n",
        "  for j in range(15):\n",
        "    classPreds.append(predictions[i][j][0])\n",
        "  imagePreds.append(classPreds)\n",
        "\n",
        "class_names = [\"Arched_Eyebrows\", \"Bags_Under_Eyes\", \"Bangs\", \"Black_Hair\", \"Blond_Hair\", \"Brown_Hair\", \"Eyeglasses\", \"Gray_Hair\", \"Heavy_Makeup\", \"High_Cheekbones\", \"Mouth_Slightly_Open\", \"Mustache\", \"Narrow_Eyes\", \"Rosy_Cheeks\", \"Smiling\", \"Straight_Hair\", \"Wavy_Hair\", \"Wearing_Earrings\", \"Wearing_Hat\", \"Wearing_Lipstick\", \"Wearing_Necklace\"]\n",
        "filenames = test['filenames'][:15]\n",
        "#print(imagePreds)\n",
        "\n",
        "for i in range(15):\n",
        "  image = []\n",
        "  for j in range(21):\n",
        "    image.append(imagePreds[j][i])\n",
        "  #print(image)\n",
        "  sorted_indices = np.argsort(image)\n",
        "  #print(sorted_indices)\n",
        "  top_three_indices = sorted_indices[::-1][:3]\n",
        "  #print(top_three_indices[0])\n",
        "  top_three_arr = [image[x] for x in top_three_indices]\n",
        "  #print(top_three_arr)\n",
        "  xLabel = f\"{class_names[sorted_indices[20]]}, {'%.2f' % (top_three_arr[0]*100)}%; {class_names[sorted_indices[19]]}, {'%.2f' % (top_three_arr[1]*100)}%; {class_names[sorted_indices[18]]}, {'%.2f' % (top_three_arr[2]*100)}%\"\n",
        "  #xLabel = ['\\n'.join(wrap(l, 20)) for l in xLabel]\n",
        "  # Plot the results\n",
        "  plt.figure(figsize=(6, 12))\n",
        "  #plt.subplot(16, 14, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(Image.open(os.path.join(img_dir, filenames.iloc[i])))\n",
        "  plt.xlabel(xLabel)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fV7q5QG4FhO"
      },
      "outputs": [],
      "source": [
        "# set Matplotlib defaults\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=16, titlepad=10)\n",
        "plt.rc('image', cmap='magma')\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# convert history.history object to dataframe\n",
        "history_frame = pd.DataFrame(history.history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpGpMZ3HfDza"
      },
      "outputs": [],
      "source": [
        "print(history_frame)\n",
        "history_frame.to_csv('/content/drive/My Drive/CelebA/Saved_models/Set_B/metrics/modelB_15.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZufnzIZvcSjS"
      },
      "outputs": [],
      "source": [
        "\n",
        "history_frame.loc[:, [\n",
        "                  'val_High_Cheekbones_accuracy',\n",
        "                  'val_Smiling_accuracy',\n",
        "                  'val_Mouth_Slightly_Open_accuracy',\n",
        "                     ]].plot()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.legend(loc='center left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVld1KN43ALB"
      },
      "outputs": [],
      "source": [
        "\n",
        "history_frame.loc[:, [\n",
        "                  'val_High_Cheekbones_loss',\n",
        "                  'val_Mouth_Slightly_Open_loss',\n",
        "                  'val_Smiling_loss',\n",
        "                     ]].plot()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8oRUY9BvrMd"
      },
      "outputs": [],
      "source": [
        "val_accuracies = []\n",
        "for col_name in history_frame.columns:\n",
        "    if col_name.startswith('val_') and col_name.endswith('accuracy'):\n",
        "        val_accuracies.append(history_frame[col_name])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDUkgN563yrU"
      },
      "outputs": [],
      "source": [
        "val_losses = []\n",
        "for col_name in history_frame.columns:\n",
        "    if col_name.startswith('val_') and col_name.endswith('loss'):\n",
        "        val_losses.append(history_frame[col_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmLwNVdhumX1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "avg_val_losses = np.mean(val_losses, axis=0)\n",
        "avg_val_accuracies = np.mean(val_accuracies, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSNoYkxbupD8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(avg_val_losses)\n",
        "plt.title('Average Validation Loss. vs. Epochs (Set 6)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(avg_val_accuracies)\n",
        "plt.title('Average Validation Acc. vs. Epochs (Set 6)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Validation Accuracy')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piwzRwmI-WKP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
