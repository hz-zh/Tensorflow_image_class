{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/content/drive/My Drive/CelebA/Img/img_align_celeba_32500'\n",
    "# Load labels.csv\n",
    "labels_df = pd.read_csv('/content/drive/My Drive/CelebA/Anno/labels_even.csv', header=0) \n",
    "\n",
    "# Load list_bbox_celeba.txt\n",
    "bbox_df = pd.read_csv('/content/drive/My Drive/CelebA/Anno/list_bbox_celeba.txt', delim_whitespace=True, header=0, dtype=object) \n",
    "\n",
    "# rename column 'image_id' of bbox_df to 'Filename'\n",
    "bbox_df.rename(columns={'image_id': 'Filename'}, inplace=True)\n",
    "\n",
    "# Convert 'x_1', 'y_1', 'width' and 'height' columns of bbox_df to numeric\n",
    "bbox_df['x_1'] = pd.to_numeric(bbox_df['x_1'])\n",
    "bbox_df['y_1'] = pd.to_numeric(bbox_df['y_1'])\n",
    "bbox_df['width'] = pd.to_numeric(bbox_df['width'])\n",
    "bbox_df['height'] = pd.to_numeric(bbox_df['height'])\n",
    "\n",
    "# Merge labels_df and bbox_df\n",
    "merged_df = pd.merge(labels_df, bbox_df, on='Filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['x_normalized'] = merged_df['x_1'] / merged_df['width']\n",
    "merged_df['y_normalized'] = merged_df['y_1'] / merged_df['height']\n",
    "merged_df['width_normalized'] = merged_df['width'] / merged_df['width']\n",
    "merged_df['height_normalized'] = merged_df['height'] / merged_df['height']\n",
    "\n",
    "# remove columns 'x_1', 'y_1', 'width' and 'height'\n",
    "merged_df.drop(['x_1', 'y_1', 'width', 'height'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, batch_size, image_size, class_names):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.class_names = class_names\n",
    "        self.num_classes = len(class_names)\n",
    "        self.indexes = np.arange(len(dataframe))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        batch_data = self.dataframe.iloc[batch_indexes]\n",
    "\n",
    "        batch_images = []\n",
    "        batch_classes = []\n",
    "\n",
    "        for _, row in batch_data.iterrows():\n",
    "            image = cv2.imread(img_dir + '/' + row['Filename'])\n",
    "            if image is None:\n",
    "                print(f\"Error loading image: {row['Filename']}\")\n",
    "                continue\n",
    "            \n",
    "            # Resize image to desired size\n",
    "            #image = cv2.resize(image, self.image_size)\n",
    "            # Normalize image\n",
    "            image = image.astype('float32') / 255.0\n",
    "             \n",
    "            class_vector = [row[class_name] for class_name in self.class_names]  # Get class labels\n",
    "            one_hot_class = tf.keras.utils.to_categorical(class_vector, num_classes=self.num_classes)\n",
    "            batch_images.append(image)\n",
    "            batch_classes.append(class_vector)\n",
    "\n",
    "        # Convert lists to NumPy arrays\n",
    "        batch_of_images = np.array(batch_images)\n",
    "        batch_of_classes = np.array(batch_classes)\n",
    "\n",
    "        return (\n",
    "            batch_of_images,\n",
    "            batch_of_classes\n",
    "        )\n",
    "\n",
    "# List of class names\n",
    "class_names = labels_df.columns[1:].tolist()\n",
    "print(class_names)\n",
    "\n",
    "# Image size\n",
    "image_size = (218,178)\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create data generator\n",
    "data_generator = CustomImageDataGenerator(merged_df, batch_size, image_size, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "image = cv2.imread(img_dir + '/' + '000001.jpg')\n",
    "image = image.astype('float32') / 255.0\n",
    "# view the shape of the image\n",
    "print(image.shape)\n",
    "# view the image\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_images, batch_data in data_generator:\n",
    "        # Train your model using batch_images and batch_data\n",
    "        model.train_on_batch(batch_images, [batch_data['class_names'], batch_data['bboxes']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images_and_bboxes(images, bboxes, target_size):\n",
    "    cropped_images = []\n",
    "    for image, bbox in zip(images, bboxes):\n",
    "        x, y, width, height = bbox\n",
    "        x_min = int(x * image.shape[1])\n",
    "        y_min = int(y * image.shape[0])\n",
    "        x_max = int((x + width) * image.shape[1])\n",
    "        y_max = int((y + height) * image.shape[0])\n",
    "        \n",
    "        cropped_image = image[y_min:y_max, x_min:x_max]\n",
    "        resized_image = cv2.resize(cropped_image, target_size)\n",
    "        \n",
    "        cropped_images.append(resized_image)\n",
    "    \n",
    "    return np.array(cropped_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def debug_data_generator(generator):\n",
    "    # Generate one batch of data\n",
    "    batch_of_images, batch_of_classes = generator[0]\n",
    "    print(\"Batch Images Shape:\", batch_of_images.shape)\n",
    "    print(\"Batch Classes Shape:\", batch_of_classes.shape)\n",
    "    print(\"Batch Images Type:\", type(batch_of_images))\n",
    "    print(\"Batch Classes Type:\", type(batch_of_classes))\n",
    "    \n",
    "    # Calculate the number of rows and columns for the grid layout\n",
    "    num_images = batch_of_images.shape[0]\n",
    "    num_cols = 5  # You can adjust the number of columns in the grid\n",
    "    num_rows = math.ceil(num_images / num_cols)\n",
    "    \n",
    "    # Set up the grid layout\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n",
    "    \n",
    "    # Iterate over images and labels, and display them in the grid\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_images:\n",
    "            ax.imshow(batch_of_images[i],cmap='Accent')\n",
    "            ax.set_title(\"Class Labels: \" + str(batch_of_classes[i]))\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')  # Turn off empty subplots if any\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming you have already created the data generator\n",
    "data_generator = CustomImageDataGenerator(merged_df, batch_size, image_size, class_names)\n",
    "\n",
    "# Call the debug function to inspect a batch\n",
    "debug_data_generator(data_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "# Load pre-trained VGG16 model without top layers\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(218, 178, 3)\n",
    ")\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Define input layer (adjust the shape based on your input images)\n",
    "input_tensor = Input(shape=(218, 178, 3), name='batch_output')\n",
    "\n",
    "# Pass input through VGG16 base model\n",
    "x = base_model(input_tensor)\n",
    "\n",
    "# Add GlobalAveragePooling2D layer to reduce spatial dimensions\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add output layer for class predictions\n",
    "class_output = Dense(num_classes, activation='softmax', name='class_output')(x)\n",
    "\n",
    "# Create the model with a specific name\n",
    "model = Model(inputs=input_tensor, outputs=class_output, name='VGG16_transfer')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Number of epochs for training\n",
    "epochs = 10\n",
    "\n",
    "# Initialize timer for overall training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Record start time for the epoch\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Initialize timer for epoch time\n",
    "    batch_start_time = time.time()\n",
    "    \n",
    "    # Iterate through batches in the generator\n",
    "    for batch_images, batch_classes in data_generator:\n",
    "        # Record start time for the batch\n",
    "        batch_start_time = time.time()\n",
    "        \n",
    "        # Train your model using batch_images and batch_data\n",
    "        losses = model.train_on_batch(x=batch_images, y=batch_classes,reset_metrics=False)\n",
    "        \n",
    "        # Record end time for the batch\n",
    "        batch_end_time = time.time()\n",
    "        batch_time = batch_end_time - batch_start_time  # Calculate time taken for the batch\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}, Batch Time: {batch_time:.2f}s, Losses: {losses}')\n",
    "    \n",
    "    # Record end time for the epoch\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_time = epoch_end_time - epoch_start_time  # Calculate time taken for the epoch\n",
    "    \n",
    "    print(f'Epoch {epoch + 1} took {epoch_time:.2f} seconds.')\n",
    "    \n",
    "# Calculate total training time\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f'Training completed in {total_time:.2f} seconds.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
