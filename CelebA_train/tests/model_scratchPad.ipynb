{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "ZsGyNr2trUVK",
        "outputId": "4f1dc22f-83e2-41e3-acfb-58f62c8f2fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: Keras-Preprocessing 1.1.2\n",
            "Uninstalling Keras-Preprocessing-1.1.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.9/dist-packages/Keras_Preprocessing-1.1.2.dist-info/*\n",
            "    /usr/local/lib/python3.9/dist-packages/keras_preprocessing/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/keras-team/keras-preprocessing.git\n",
            "  Cloning https://github.com/keras-team/keras-preprocessing.git to /tmp/pip-req-build-8l8134kl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/keras-team/keras-preprocessing.git /tmp/pip-req-build-8l8134kl\n",
            "  Resolved https://github.com/keras-team/keras-preprocessing.git to commit 3e380065d4afc7347aaee8d89325a16b22158438\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from Keras-Preprocessing==1.1.2) (1.22.4)\n",
            "Building wheels for collected packages: Keras-Preprocessing\n",
            "  Building wheel for Keras-Preprocessing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Keras-Preprocessing: filename=Keras_Preprocessing-1.1.2-py3-none-any.whl size=43629 sha256=9c5c0e1a65cd2af95ebe4027b861034ed22c7d77661123d3f052184b8b049225\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d4f99vfb/wheels/42/2c/ab/f514e37fef847aece28f74782c8adb23ddd1d0e60d71da4f42\n",
            "Successfully built Keras-Preprocessing\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras_preprocessing"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall keras-preprocessing\n",
        "%pip install git+https://github.com/keras-team/keras-preprocessing.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sG8mfnmRrUVO"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "\"\"\"Import from keras_preprocessing not from keras.preprocessing, because Keras may or may not contain the features discussed here depending upon when you read this article, until the keras_preprocessed library is updated in Keras use the github version.\"\"\"\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AiVNRawrUVO",
        "outputId": "b5741639-37dc-43a6-f53b-6ceda986f735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9MlyllprUVP"
      },
      "outputs": [],
      "source": [
        "# Set variable to image directory\n",
        "img_dir = '/content/drive/My Drive/CelebA/Img/img_align_celeba_6500'\n",
        "\n",
        "# Define list of class names (subset of the classes listed in `list_attr_celeba.txt`)\n",
        "class_names = ['Arched_Eyebrows', 'Bags_Under_Eyes', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Eyeglasses', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'Rosy_Cheeks', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace']\n",
        "\n",
        "# Define df as a dataframe from directory \n",
        "df=pd.read_csv('/content/drive/My Drive/CelebA/Anno/labels.csv', header=0, delimiter=',', usecols=None)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY64sK39Vl5H",
        "outputId": "8dd7ef0f-c0bd-4e18-bcb1-d9536d674694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "000001.jpg\n",
            "/content/drive/My Drive/CelebA/Img/img_align_celeba_6500/000001.jpg\n",
            "(218, 178, 3)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "file_id=df['filenames'].iloc[0]\n",
        "print (file_id)\n",
        "sdir=r'/content/drive/My Drive/CelebA/Img/img_align_celeba_6500'\n",
        "file_path=os.path.join(sdir, file_id) # should be full path to the image file\n",
        "print(file_path)\n",
        "try:\n",
        "    image=cv2.imread(file_path)\n",
        "    shape=image.shape\n",
        "    print(shape)\n",
        "except:\n",
        "    print('Invalid image file')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH6sVDYhCMb4",
        "outputId": "216d9c16-45de-47d9-f5b3-41d7c0cfe08a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CelebA/Img/img_align_celeba_6500\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "abs_img_dir = os.path.abspath(img_dir)\n",
        "print(abs_img_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Gi4DgRFrUVP",
        "outputId": "614d65ce-ed35-4eff-d560-98e1017acd2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4500 validated image filenames.\n",
            "Found 1000 validated image filenames.\n",
            "Found 1000 validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255.)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "train_generator=datagen.flow_from_dataframe(\n",
        "dataframe=df[:4500],\n",
        "directory=img_dir,\n",
        "x_col='filenames',\n",
        "y_col=class_names,\n",
        "save_format= 'jpg',\n",
        "batch_size=32,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"raw\",\n",
        "#classes=class_names,\n",
        "target_size=(100,100))\n",
        "\n",
        "valid_generator=test_datagen.flow_from_dataframe(\n",
        "dataframe=df[4500:5500],\n",
        "directory=img_dir,\n",
        "x_col='filenames',\n",
        "y_col=class_names,\n",
        "save_format= 'jpg',\n",
        "batch_size=32,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"raw\",\n",
        "#classes=[\"Arched_Eyebrows\", \"Bags_Under_Eyes\", \"Bangs\", \"Black_Hair\", \"Blond_Hair\", 'Brown_Hair', 'Eyeglasses', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'Rosy_Cheeks', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace'],\n",
        "target_size=(100,100))\n",
        "\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "dataframe=df[5500:],\n",
        "directory=img_dir,\n",
        "x_col='filenames',\n",
        "batch_size=1,\n",
        "seed=42,\n",
        "shuffle=False,\n",
        "class_mode=None,\n",
        "target_size=(100,100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P0zMo8_rUVQ",
        "outputId": "ab532e8d-3e60-44cb-e559-477744f535d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "inp = Input(shape = (100,100,3))\n",
        "x = Conv2D(32, (3, 3), padding = 'same')(inp)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(32, (3, 3))(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D(pool_size = (2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Conv2D(64, (3, 3), padding = 'same')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(64, (3, 3))(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D(pool_size = (2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512)(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# define 21 outputs\n",
        "output1 = Dense(1, activation = 'sigmoid')(x)\n",
        "output2 = Dense(1, activation = 'sigmoid')(x)\n",
        "output3 = Dense(1, activation = 'sigmoid')(x)\n",
        "output4 = Dense(1, activation = 'sigmoid')(x)\n",
        "output5 = Dense(1, activation = 'sigmoid')(x)\n",
        "output6 = Dense(1, activation = 'sigmoid')(x)\n",
        "output7 = Dense(1, activation = 'sigmoid')(x)\n",
        "output8 = Dense(1, activation = 'sigmoid')(x)\n",
        "output9 = Dense(1, activation = 'sigmoid')(x)\n",
        "output10 = Dense(1, activation = 'sigmoid')(x)\n",
        "output11 = Dense(1, activation = 'sigmoid')(x)\n",
        "output12 = Dense(1, activation = 'sigmoid')(x)\n",
        "output13 = Dense(1, activation = 'sigmoid')(x)\n",
        "output14 = Dense(1, activation = 'sigmoid')(x)\n",
        "output15 = Dense(1, activation = 'sigmoid')(x)\n",
        "output16 = Dense(1, activation = 'sigmoid')(x)\n",
        "output17 = Dense(1, activation = 'sigmoid')(x)\n",
        "output18 = Dense(1, activation = 'sigmoid')(x)\n",
        "output19 = Dense(1, activation = 'sigmoid')(x)\n",
        "output20 = Dense(1, activation = 'sigmoid')(x)\n",
        "output21 = Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "# define multi-output model\n",
        "model = Model(inputs = inp, outputs = [output1, output2, output3, output4, output5, output6, output7, output8, output9, output10, output11, output12, output13, output14, output15, output16, output17, output18, output19, output20, output21])\n",
        "model.compile(\n",
        "   optimizers.Adam(lr = 0.0001, decay = 1e-6),\n",
        "   loss = [\"binary_crossentropy\",\"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\", \"binary_crossentropy\"], \n",
        "   metrics = [\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5gEpNBmrrUVV"
      },
      "outputs": [],
      "source": [
        "# \n",
        "def generator_wrapper(generator):\n",
        "    for batch_x,batch_y in generator:\n",
        "        yield (batch_x,[batch_y[:,i] for i in range(21)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_6nvdNyrUVZ",
        "outputId": "e3055aa0-790b-489d-82ff-d8ad50b551bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "140/140 - 1024s - loss: 11.5089 - dense_1_loss: 0.5509 - dense_2_loss: 0.5472 - dense_3_loss: 0.5508 - dense_4_loss: 0.5478 - dense_5_loss: 0.5488 - dense_6_loss: 0.5466 - dense_7_loss: 0.5493 - dense_8_loss: 0.5481 - dense_9_loss: 0.5481 - dense_10_loss: 0.5479 - dense_11_loss: 0.5465 - dense_12_loss: 0.5449 - dense_13_loss: 0.5478 - dense_14_loss: 0.5459 - dense_15_loss: 0.5484 - dense_16_loss: 0.5469 - dense_17_loss: 0.5484 - dense_18_loss: 0.5471 - dense_19_loss: 0.5488 - dense_20_loss: 0.5475 - dense_21_loss: 0.5511 - dense_1_accuracy: 0.7710 - dense_2_accuracy: 0.7725 - dense_3_accuracy: 0.7704 - dense_4_accuracy: 0.7748 - dense_5_accuracy: 0.7714 - dense_6_accuracy: 0.7736 - dense_7_accuracy: 0.7732 - dense_8_accuracy: 0.7729 - dense_9_accuracy: 0.7740 - dense_10_accuracy: 0.7726 - dense_11_accuracy: 0.7736 - dense_12_accuracy: 0.7747 - dense_13_accuracy: 0.7710 - dense_14_accuracy: 0.7745 - dense_15_accuracy: 0.7722 - dense_16_accuracy: 0.7729 - dense_17_accuracy: 0.7737 - dense_18_accuracy: 0.7713 - dense_19_accuracy: 0.7740 - dense_20_accuracy: 0.7721 - dense_21_accuracy: 0.7737 - val_loss: 11.8521 - val_dense_1_loss: 0.5815 - val_dense_2_loss: 0.5633 - val_dense_3_loss: 0.5267 - val_dense_4_loss: 0.6007 - val_dense_5_loss: 0.5085 - val_dense_6_loss: 0.5497 - val_dense_7_loss: 0.4863 - val_dense_8_loss: 0.4817 - val_dense_9_loss: 0.6298 - val_dense_10_loss: 0.6790 - val_dense_11_loss: 0.7086 - val_dense_12_loss: 0.4842 - val_dense_13_loss: 0.5172 - val_dense_14_loss: 0.4684 - val_dense_15_loss: 0.6948 - val_dense_16_loss: 0.5664 - val_dense_17_loss: 0.6005 - val_dense_18_loss: 0.5345 - val_dense_19_loss: 0.4877 - val_dense_20_loss: 0.6758 - val_dense_21_loss: 0.5069 - val_dense_1_accuracy: 0.7419 - val_dense_2_accuracy: 0.8125 - val_dense_3_accuracy: 0.8518 - val_dense_4_accuracy: 0.7732 - val_dense_5_accuracy: 0.8579 - val_dense_6_accuracy: 0.7873 - val_dense_7_accuracy: 0.9264 - val_dense_8_accuracy: 0.9577 - val_dense_9_accuracy: 0.6310 - val_dense_10_accuracy: 0.5625 - val_dense_11_accuracy: 0.5353 - val_dense_12_accuracy: 0.9546 - val_dense_13_accuracy: 0.8730 - val_dense_14_accuracy: 0.9506 - val_dense_15_accuracy: 0.5433 - val_dense_16_accuracy: 0.7954 - val_dense_17_accuracy: 0.6915 - val_dense_18_accuracy: 0.8327 - val_dense_19_accuracy: 0.9365 - val_dense_20_accuracy: 0.5464 - val_dense_21_accuracy: 0.8831 - 1024s/epoch - 7s/step\n"
          ]
        }
      ],
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "\n",
        "history = model.fit((train_generator),\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=generator_wrapper(valid_generator),\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=1,\n",
        "                    verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn8clI2lrUVa",
        "outputId": "75ab5bff-287a-4429-ffb5-082b09797ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 38s 38ms/step\n"
          ]
        }
      ],
      "source": [
        "test_generator.reset()\n",
        "pred=model.predict(test_generator,\n",
        "steps=STEP_SIZE_TEST,\n",
        "verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot learning curves\n",
        "import pandas as pd\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, ['loss', \n",
        "                     'val_output1_accuracy',\n",
        "                     'val_output2_accuracy',\n",
        "                     'val_output3_accuracy',\n",
        "                     'val_output4_accuracy',\n",
        "                     'val_output5_accuracy',]].plot()\n",
        "                     history_frame.loc[:, ['loss',\n",
        "                     'val_output6_accuracy',\n",
        "                     'val_output7_accuracy',\n",
        "                     'val_output8_accuracy',\n",
        "                     'val_output9_accuracy',\n",
        "                     'val_output10_accuracy',]].plot()\n",
        "                     history_frame.loc[:, ['loss',\n",
        "                     'val_output11_accuracy',\n",
        "                     'val_output12_accuracy',\n",
        "                     'val_output13_accuracy',\n",
        "                     'val_output14_accuracy',\n",
        "                     'val_output15_accuracy',]].plot()\n",
        "                     history_frame.loc[:, ['loss',\n",
        "                     'val_output16_accuracy',\n",
        "                     'val_output17_accuracy',\n",
        "                     'val_output18_accuracy',\n",
        "                     'val_output19_accuracy',\n",
        "                     'val_output20_accuracy',\n",
        "                     'val_output21_accuracy',]].plot()\n",
        "history_frame.loc[:, ['accuracy',\n",
        "                     'dense_1_accuracy',\n",
        "                     'dense_2_accuracy',\n",
        "                     'dense_3_accuracy',\n",
        "                     'dense_4_accuracy',\n",
        "                     'dense_5_accuracy',\n",
        "                     'dense_6_accuracy',\n",
        "                     'dense_7_accuracy',\n",
        "                     'dense_8_accuracy',\n",
        "                     'dense_9_accuracy',\n",
        "                     'dense_10_accuracy',\n",
        "                      ]].plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss={'output1': 'binary_crossentropy', \n",
        "              'output2': 'binary_crossentropy',\n",
        "               'output3': 'binary_crossentropy',\n",
        "               'output4': 'binary_crossentropy',\n",
        "               'output5': 'binary_crossentropy',\n",
        "               'output6': 'binary_crossentropy',\n",
        "               'output7': 'binary_crossentropy',\n",
        "               'output8': 'binary_crossentropy',\n",
        "               'output9': 'binary_crossentropy',\n",
        "               'output10': 'binary_crossentropy',\n",
        "               'output11': 'binary_crossentropy',\n",
        "               'output12': 'binary_crossentropy',\n",
        "               'output13': 'binary_crossentropy',\n",
        "               'output14': 'binary_crossentropy',\n",
        "               'output15': 'binary_crossentropy',\n",
        "               'output16': 'binary_crossentropy',\n",
        "               'output17': 'binary_crossentropy',\n",
        "               'output18': 'binary_crossentropy',\n",
        "               'output19': 'binary_crossentropy',\n",
        "               'output20': 'binary_crossentropy',\n",
        "              'output21': 'binary_crossentropy'},\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "layerNames= ['Arched_Eyebrows', 'Bags_Under_Eyes', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Eyeglasses', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'Rosy_Cheeks', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace']\n",
        "history_frame.loc[:, [ \n",
        "                  'val_Arched_Eyebrows_accuracy',\n",
        "                  'val_Bags_Under_Eyes_accuracy',\n",
        "                  'val_Bangs_accuracy',\n",
        "                  'val_Black_Hair_accuracy',\n",
        "                  'val_Blond_Hair_accuracy',\n",
        "                     ]].plot()\n",
        "history_frame.loc[:, [\n",
        "                  'val_Brown_Hair_accuracy',\n",
        "                  'val_Eyeglasses_accuracy',\n",
        "                  'val_Gray_Hair_accuracy',\n",
        "                  'val_Heavy_Makeup_accuracy',\n",
        "                  'val_High_Cheekbones_accuracy',\n",
        "                     ]].plot()\n",
        "history_frame.loc[:, [\n",
        "                  'val_Mouth_Slightly_Open_accuracy',\n",
        "                  'val_Mustache_accuracy',\n",
        "                  'val_Narrow_Eyes_accuracy',\n",
        "                  'val_Rosy_Cheeks_accuracy',\n",
        "                  'val_Smiling_accuracy',\n",
        "                     ]].plot()\n",
        "history_frame.loc[:, [\n",
        "                  'val_Straight_Hair_accuracy',\n",
        "                  'val_Wavy_Hair_accuracy',\n",
        "                  'val_Wearing_Earrings_accuracy',\n",
        "                  'val_Wearing_Hat_accuracy',\n",
        "                  'val_Wearing_Lipstick_accuracy',\n",
        "                  'val_Wearing_Necklace_accuracy',\n",
        "                  ]].plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set x axis to 'epochs' and y axis to 'val_accuracy'\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Val_Accuracy')\n",
        "import pandas as pd\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, [ \n",
        "                  'val_Arched_Eyebrows_accuracy',\n",
        "                  'val_Bags_Under_Eyes_accuracy',\n",
        "                  'val_Bangs_accuracy',\n",
        "                  'val_Black_Hair_accuracy',\n",
        "                  'val_Blond_Hair_accuracy',\n",
        "                     ]].plot()\n",
        "history_frame.loc[:, [\n",
        "                  'val_Brown_Hair_accuracy',\n",
        "                  'val_Eyeglasses_accuracy',\n",
        "                  'val_Gray_Hair_accuracy',\n",
        "                  'val_Heavy_Makeup_accuracy',\n",
        "                  'val_High_Cheekbones_accuracy',\n",
        "                     ]].plot()\n",
        "history_frame.loc[:, [\n",
        "                  'val_Mouth_Slightly_Open_accuracy',\n",
        "                  'val_Mustache_accuracy',\n",
        "                  'val_Narrow_Eyes_accuracy',\n",
        "                  'val_Rosy_Cheeks_accuracy',\n",
        "                  'val_Smiling_accuracy',\n",
        "                     ]].plot()\n",
        "history_frame.loc[:, [\n",
        "                  'val_Straight_Hair_accuracy',\n",
        "                  'val_Wavy_Hair_accuracy',\n",
        "                  'val_Wearing_Earrings_accuracy',\n",
        "                  'val_Wearing_Hat_accuracy',\n",
        "                  'val_Wearing_Lipstick_accuracy',\n",
        "                  'val_Wearing_Necklace_accuracy',\n",
        "                  ]].plot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
